<%
import org.json4s._
import org.json4s.jackson.JsonMethods._

import org.json4s.{DefaultFormats, JNothing}
import org.json4s.jackson.JsonMethods.{compact, parse}
import org.json4s.jackson.{JsonMethods}
import org.json4s.jackson.Serialization.{read}

import scala.collection.mutable.ListBuffer
import scala.io.Source.fromFile
import scala.xml._
import org.apache.spark.sql.catalyst.parser.CatalystSqlParser

import ru.neoflex.datalog.engine.Parser

val pathToConfJson = 	"C:\\projects\\temp\\alfabank\\bki\\C5486671.Обогащение данных введённых в область dmin_risk\\oozie_workflows\\reg\\wf_reg_imbr_cre_req_deriveddata_daily\\conf\\conf.json"
val pathToSql = 		"C:\\projects\\temp\\alfabank\\bki\\C5486671.Обогащение данных введённых в область dmin_risk\\hdfs_home\\scripts\\imbr_request"
val pathToWorkflowXml = "C:\\projects\\temp\\alfabank\\bki\\C5486674.Выгрузка данных в БД витрина данных рисков\\oozie_workflows\\ctl\\wf_ctl_export_imbr_cre_req_daily\\workflow.xml"

val data = parse(fromFile(pathToConfJson).getLines.mkString)

val v = data
val tables = v \ "tables"
case class FileDictionary(name: String = null, path: String = null)
case class Table(name: Option[String], sql: String = "",
	regViews: List[FileDictionary] = List(),
	csvDicts: List[FileDictionary] = List(),
	inTables: List[String] = List())
val bkiTablesBuffer = new ListBuffer[Table]()
val list = tables.values.asInstanceOf[Map[String, Map[String, _]]]
implicit val formats = DefaultFormats
list.keySet.foreach(s => {
	val tableJ = v \ "tables" \ s
	val table = read[Table](compact(JsonMethods.render(tableJ)))

	val regViews = v \ "tables" \ s \ "reg_views"
	val regViewsBuffer = new ListBuffer[FileDictionary]()
	if(regViews != JNothing) {
		val regViewlist = regViews.values.asInstanceOf[Map[String, Map[String, _]]]
		regViewlist.keySet.foreach(ss => {
			val regViewJ = v \ "tables" \ s \ "reg_views" \ ss
			val regView = FileDictionary(ss, regViewJ.values.toString)
			regViewsBuffer += regView
		})
	}

	val dicts = v \ "tables" \ s \ "csv_dicts"
	val dictBuffer = new ListBuffer[FileDictionary]()
	if(dicts != JNothing) {
		val dlist = dicts.values.asInstanceOf[Map[String, Map[String, _]]]
		dlist.keySet.foreach(ss => {
			val dJ = v \ "tables" \ s \ "reg_views" \ ss
			val d = FileDictionary(ss, dJ.values.toString)
			dictBuffer += d
		})
	}
	val linkBuffer = new ListBuffer[String]()
	if(s == "person_request_bki_rb") {
		linkBuffer += "l_hdb_det.wsrm_log"
		linkBuffer += "source_db.source_person_request_bki_rb"
	}

	Option(table.sql).flatMap(sql => {

		linkBuffer ++= Parser.getInTables(
			CatalystSqlParser.parsePlan(
				fromFile(pathToSql + "\\" + sql).getLines.mkString("\r\n")
					.replace("{", "").replace("}", ""))
		)
		.filter(w => w.contains(".") || list.keySet.contains(w))
		.flatMap(w => {
			if(w == "source_db.imbr_table") {
				List("source_db.imbr_cre_req_rb", "source_db.imbr_cre_req_mb", "source_db.imbr_cre_comp_req")
			} else {
				if (w.contains("syscode")) {
					List(w.replace("syscode", "mb"), w.replace("syscode", "rb"))
				} else {
					List(w)
				}
			}
		})
/*
		val sqlFileLines = fromFile(pathToSql + "\\" + sql).getLines
		sqlFileLines.filter(_.contains("from {source_db}")).foreach(line => {
			val foundTableName = line.trim().replace("from {source_db}.", "").split(' ')(0)
			val tableNames = new ListBuffer[String]()
			if(!foundTableName.contains("{syscode}")) {
				tableNames += foundTableName
			} else {
				tableNames += foundTableName.replace("{syscode}", "rb")
				tableNames += foundTableName.replace("{syscode}", "mb")
			}
			tableNames.foreach(tableName => {
				if(tableName != s) {
					if(!linkBuffer.contains(tableName)) {
						linkBuffer += tableName
					}
				}
			})
		})
		val sqlText = fromFile(pathToSql + "\\" + sql).getLines.mkString
		list.keySet.foreach(temp => {
			if (sqlText.contains(temp)) {
				if(temp != s) {
					if(!linkBuffer.contains(temp)) {
						linkBuffer += temp
					}
				}
			}
		})*/

		None
	})

	val table2 = Table(Some(s), table.sql, regViewsBuffer.toList, dictBuffer.toList, linkBuffer.distinct.toList)
	bkiTablesBuffer += table2
})

val xml = XML.loadFile(pathToWorkflowXml)
val elist = (xml \\ "action").filter(a =>  (a \ "@name").toString().contains("wf_export_imbr_imbr_cre") )
val etables = for {
	a <- elist
	p <- (a \\ "sub-workflow" \\ "configuration" \\ "property")
	if !(p \\ "name").find(n => n.text == "table_name").isEmpty
} yield ((a \ "@name").toString().replace("wf_export_imbr_", ""), (p \ "value").map(_.text))

val exportTables = etables.distinct.toList
val bkiTables = bkiTablesBuffer.toList
%>
{
"datasets":
	[
	#for (i <- 0 to bkiTables.size - 1)
		{
			"name": "${bkiTables(i).name}",
			"layer": "DataMart",
			"project": "BKI",
			"in": [
				#for (j <- 0 to bkiTables(i).regViews.size - 1)
					{
						"name": "${bkiTables(i).regViews(j).name}",
						"layer": "Hive",
						"project": "BKI",
						"datasetType": "file",
						"pathToData": "${bkiTables(i).regViews(j).path}"
					}#if(j != bkiTables(i).regViews.size - 1), #elseif (bkiTables(i).csvDicts.size > 0), #elseif(bkiTables(i).inTables.size > 0), #end
				#end
				#for (j <- 0 to bkiTables(i).csvDicts.size - 1)
					{
					"name": "${bkiTables(i).csvDicts(j).name}",
					"layer": "Hive",
					"project": "BKI",
					"datasetType": "file",
					"pathToData": "${bkiTables(i).csvDicts(j).path}"
					}#if(j != bkiTables(i).csvDicts.size - 1), #elseif (bkiTables(i).inTables.size > 0), #end
				#end
				#for (j <- 0 to bkiTables(i).inTables.size - 1)
					{
					"name": "${bkiTables(i).inTables(j)}",
					"layer": "Hive",
					"project": "BKI"
					}#if(j != bkiTables(i).inTables.size - 1), #end
				#end
			]
		},
	#end
	#for (j <- 0 to exportTables.size - 1)
		{
			"name": "${exportTables(j)._2}",
			"layer": "External",
			"project": "BKI",
			"in": [
				{
					"name": "${exportTables(j)._1}",
					"layer": "DataMart",
					"project": "BKI"
				}
			]
		}#if(j != exportTables.size - 1), #end
	#end
	]
}