<%
	import java.io.File
	import scala.collection.mutable.ListBuffer
	import scala.io.Source.fromFile
	import scala.io.Codec
	import scala.util.control.Breaks._
	import scala.io.Source
	import org.json4s._
	import org.json4s.jackson.JsonMethods._
	import ru.neoflex.datalog.engine.Parser
	import scala.xml._
	import org.apache.spark.sql.catalyst.parser.CatalystSqlParser
	%>
<%@ val params: Option[String] = None%>
<%
	implicit val formats = DefaultFormats

	implicit val codec = Codec("UTF8")

var path = "C:/projects/temp/alfabank/cr_ow_qa/"
var project = "qa"
var sourceFilePrefix = ""
params.map(s => {
	val j = parse(s)
	path = (j \ "folder").extract[String]
	project = (j \ "project").extract[String]
	sourceFilePrefix = (j \ "sourcePrefix").extract[String]
})

case class QaTable(targetName: String, files: String, inTables: List[String], sourceFile: String, sqlSource: String)

def getText(path: String): String ={
	val source = fromFile(path)
	try {
		source.getLines.mkString("\r\n")
	} finally {
		source.close()
	}
}

val qatables = new ListBuffer[QaTable]()

Seq(
	path + "/oozie_workflows/atom/wf_deriveddata_qa_ow_prod_data/",
	path + "/oozie_workflows/atom/wf_deriveddata_qa_connector_data/"
).foreach(folder => {
	val xml = XML.loadFile(folder + "/workflow.xml")

	val sqoopArgs = xml \\ "sqoop" \\ "arg"
	val inTables = sqoopArgs
		.find(x => x.text == "--query")
		.flatMap(x => {
			Some(
				Parser.getInTables(CatalystSqlParser.parsePlan(
				sqoopArgs(sqoopArgs.indexOf(x) + 1)
				.text.replace("\"", "")
				.replace("$CONDITIONS", "1=1")
				.replace("${", "")
				.replace("}", ""))))
			}).toList.flatten

	val targetFolder = sqoopArgs.find(x => x.text == "--target-dir")
		.flatMap(x => Some(sqoopArgs(sqoopArgs.indexOf(x) + 1).text))

	val hive2script = (xml \\ "hive2" \ "script").text

	val outTables = Parser.getOutTables(CatalystSqlParser.parsePlan(
	getText(folder + hive2script)
		.replace("$CONDITIONS", "1=1")
		.replace("${", "")
		.replace("}", "")
		.replace("SET ", "--SET ")))

	targetFolder.map(x => {
		qatables += QaTable(outTables.head, x, inTables, folder + "/workflow.xml", hive2script)
		None
	})
})
%>
{
"datasets":
	[
	#for (i <- 0 to qatables.size - 1)
		{
			"name": "${qatables(i).files}",
			"layer": "Hive",
			"project": "${project}",
			"sourceFile": "${qatables(i).sourceFile}",
			"datasetType": "file",
			"in": [
			#for(j <- 0 to qatables(i).inTables.size - 1)
				{
					"name": "${qatables(i).inTables(j)}",
					"layer": "Oracle",
					"project": "${project}",
					"sourceFile": ""
				}#if(j != qatables(i).inTables.size - 1) , #end
			#end
			],
			"out": [
				{
					"name": "${qatables(i).targetName}",
					"layer": "Hive",
					"project": "${project}",
					"sourceFile": "${qatables(i).sqlSource}"
				}
			]
			}#if(i != qatables.size - 1) , #end
	#end
	,
		{
			"name": "Email",
			"datasetType": "action",
			"layer": "DataMart",
			"in": [
			#for (i <- 0 to qatables.size - 1)
				{
					"name": "${qatables(i).targetName}",
					"layer": "Hive",
					"project": "${project}",
					"sourceFile": "${qatables(i).sqlSource}"
				}#if(i != qatables.size - 1) , #end
			#end
			]
		}
	]
}
